# README: MODULAR AI COUPLES THERAPY SIMULATION

## ğŸ¯ PROJECT SUMMARY

Status: âœ… **ALL FILES CREATED & READY TO USE**

---

## ğŸ“¦ FILES CREATED (10 Modules + 2 Guides)

### Core Modules
1. âœ… **config.py** - Configuration & constants
2. âœ… **data_loader.py** - Asset loading (JSON, prompts)
3. âœ… **user_interface.py** - CLI menu system
4. âœ… **session_setup.py** - Session initialization
5. âœ… **conversation_engine.py** - Dialogue generation & speaker selection
6. âœ… **trigger_system.py** - Trigger detection (4 modalities)
7. âœ… **intervention_system.py** - LLM scoring & intervention generation
8. âœ… **panas_analyzer.py** - Emotional assessment (pre/post)
9. âœ… **output_manager.py** - File I/O & summaries
10. âœ… **main.py** - Orchestrator (ties everything together)

### Documentation
11. âœ… **REFACTORING_GUIDE.md** - Detailed module explanations
12. âœ… **QUICK_START.md** - Installation & getting started

### Utilities
11. âœ… **reproduce_panas.py** - Re-run emotional analysis
12. âœ… **verify_reasoning.py** - Test intervention logic
13. âœ… **verify_display.py** - Test console output
14. âœ… **prompts/** - Customizable agent personas & instructions

---

## ğŸš€ QUICK START

### Step 1: Copy Files to Project Directory
```
your_project/
â”œâ”€â”€ config.py
â”œâ”€â”€ data_loader.py
â”œâ”€â”€ user_interface.py
â”œâ”€â”€ session_setup.py
â”œâ”€â”€ conversation_engine.py
â”œâ”€â”€ trigger_system.py
â”œâ”€â”€ intervention_system.py
â”œâ”€â”€ panas_analyzer.py
â”œâ”€â”€ output_manager.py
â”œâ”€â”€ main.py
â”œâ”€â”€ reproduce_panas.py    <-- Optional: Analysis tool
â”œâ”€â”€ verify_reasoning.py   <-- Optional: Testing tool
â”œâ”€â”€ verify_display.py     <-- Optional: Testing tool
â”œâ”€â”€ prompts/              <-- REQUIRED: Agent personas
â”‚   â”œâ”€â”€ therapist_prompt.txt
â”‚   â”œâ”€â”€ patient_A_prompt.txt
â”‚   â”œâ”€â”€ patient_B_prompt.txt
â”‚   â”œâ”€â”€ trigger-personas.json
â”‚   â””â”€â”€ trigger-personas_PANAS_2.json
â””â”€â”€ .env (create this)
```

### Step 2: Install Dependencies
```bash
pip install openai python-dotenv
```

### Step 3: Create .env File
```
OPENAI_API_KEY=sk-your-key-here
```

### Step 4: Run
```bash
python main.py
```

---

## ğŸ“Š MODULE DEPENDENCY DIAGRAM

```
main.py (Orchestrator)
    â†“
    â”œâ”€â†’ data_loader.py (Load assets)
    â”œâ”€â†’ user_interface.py (User input)
    â”œâ”€â†’ session_setup.py (Initialize session)
    â”œâ”€â†’ conversation_engine.py (Generate dialogue)
    â”‚   â””â”€â†’ config.py (Models, temperature)
    â”œâ”€â†’ trigger_system.py (Detect triggers)
    â”œâ”€â†’ intervention_system.py (Score & generate)
    â”œâ”€â†’ panas_analyzer.py (Emotional analysis)
    â””â”€â†’ output_manager.py (Save results)
```

---

## ğŸ›ï¸ USER FLOW

```
START
  â†“
1. Select Session Topic
  â”œâ”€ ALCOHOL ABUSE
  â”œâ”€ ANXIETY
  â”œâ”€ CONFLICT
  â””â”€ (etc.)
  â†“
2. Select Temperature (0.0-1.0)
  â”œâ”€ 0.0 = Deterministic
  â”œâ”€ 0.5 = Balanced
  â””â”€ 1.0 = Creative
  â†“
3. Select Conversation Structure
  â”œâ”€ Sequential (fixed rotation)
  â”œâ”€ LLM Only (intelligent selection, no triggers)
  â””â”€ LLM with Triggers (full system) â† NEW
  â†“
4. (If LLM+Triggers) Select Trigger Type
  â”œâ”€ Direct Intervention Request
  â”œâ”€ Time-based Analysis
  â”œâ”€ Semantic Analysis
  â”œâ”€ Quantitative Analysis
  â””â”€ All Triggers
  â†“
5. (NEW!) Select First Speaker
  â”œâ”€ Patient A (affected party)
  â”œâ”€ Patient B (supporting partner)
  â”œâ”€ Random
  â†“
6. (NEW!) Persona Selection
  â”œâ”€ Random (default)
  â”œâ”€ Manual Selection (browse & choose specific personas)
  â†“
[SIMULATION RUNS: 25-35 turns]
  â†“
[POST-SESSION PANAS ANALYSIS]
  â†“
[OUTPUT: JSON transcript, summary, report]
  â†“
END
```

---

## ğŸ“‹ FEATURE BREAKDOWN

### Trigger Detection (4 Modalities)

| Trigger | Detection | Example |
|---------|-----------|---------|
| **Direct Request** | Keywords | "Can you help us?" |
| **Time-based** | Silence >30s | Speaker hasn't spoken 3+ turns |
| **Semantic** | Escalation + self-harm | "I HATE this!!! I want to die" |
| **Quantitative** | Dominance + word count | 6+ consecutive messages or 100+ words |

### Intervention Scoring (4 Dimensions)

| Dimension | Scale | Meaning |
|-----------|-------|---------|
| Flow Disruption | 0-100 | How jarring would interruption be? |
| Therapeutic Need | 0-100 | Is there genuine distress? |
| Timing | 0-100 | Is it a natural pause point? |
| Impact | 0-100 | Will it help (USR framework)? |
| **Average** | **0-100** | **Trigger threshold: â‰¥70** |
 
### Intervention Transparency
- **Reasoning**: The system now provides an explicit explanation for *why* an intervention was triggered, referencing the specific scoring dimension and observed behavior.

### PANAS Emotional Assessment

**20 Emotions measured:**
- **10 Positive**: Interested, Excited, Strong, Enthusiastic, Proud, Alert, Inspired, Determined, Attentive, Active
- **10 Negative**: Distressed, Upset, Guilty, Scared, Hostile, Irritable, Ashamed, Nervous, Jittery, Afraid

**Outcome Metrics:**
- Pre-session baseline (from persona)
- Post-session scoring (LLM evaluated)
- Delta calculation (improvement measure)

---

## ğŸ’¡ KEY INNOVATIONS

### 1. Four-Dimensional Intervention Scoring
â†’ Not just *when* to intervene (triggers), but *whether* intervening will help (clinical reasoning)

### 2. NEW: First Speaker & Persona Selection
â†’ Research design feature: control exactly *who* speaks first and *which* specific persona characteristics are active.

### 3. Modular Architecture
â†’ Test components independently (Sequential vs LLM Only vs LLM+Triggers)

### 4. PANAS Pre/Post Assessment
â†’ Empirical outcome measurement (emotional state improvement)

---

## ğŸ§ª EXPERIMENT EXAMPLES

### Experiment 1: Baseline (Sequential)
```
Structure: Sequential (Therapist â†’ Patient A â†’ Patient B cycle)
Triggers: Disabled
First Speaker: (N/A)
â†’ Output: Pure dialogue without AI interference
```

### Experiment 2: Speaker Selection
```
Structure: LLM Only
Triggers: Disabled
First Speaker: Patient A
â†’ Output: Intelligent speaker balancing
```

### Experiment 3: Full System
```
Structure: LLM with Triggers
Trigger Type: Semantic Analysis
First Speaker: Patient B
â†’ Output: Full adaptive facilitation with emotional crisis detection
```

### Experiment 4: First Speaker Ablation
```
Run 3 sessions, vary first speaker:
- Patient A first
- Patient B first
- Random

â†’ Compare PANAS deltas across sessions
```

---

## ğŸ“Š OUTPUT FILES

### Generated Files
```
transcripts/
â”œâ”€â”€ therapy_transcript_1.json          # Full session data
â”œâ”€â”€ therapy_transcript_2.json          # Next session
â”œâ”€â”€ transcript_readable_*.txt          # Human-readable format
â””â”€â”€ (auto-incremented numbering)
```

### JSON Structure
```json
{
  "session_topic_header": "ALCOHOL ABUSE",
  "conversation_structure": "LLM with Triggers",
  "first_speaker_selection": "Patient A",  â† NEW
  "session_transcript": [
    {
      "turn": 1,
      "speaker": "Therapist",
      "dialogue": "..."
    },
    ...
  ],
  "intervention_count": 3,
  "Patient_A_PANAS_DELTA": [
    {"feeling": "Interested", "before_score": 3, "after_score": 4, "difference": 1}
  ]
}
```

---

## ğŸ”§ CUSTOMIZATION

### Change Intervention Threshold
**File**: `config.py`
```python
INTERVENTION_THRESHOLD = 70  # Change to 50, 60, 80, etc.
```

### Add New Trigger Type
**File**: `trigger_system.py`
```python
def detect_my_trigger(message):
    return "pattern" in message.lower()

# In detect_triggers():
if selected_trigger == "My Trigger":
    if detect_my_trigger(current_message):
        triggers_detected.append({...})
```

### Change Model
**File**: `config.py`
```python
CONVERSATION_MODEL = "gpt-4-turbo"  # Or any OpenAI model
```

### Prompt & Persona Customization

**1. System Prompts (`prompts/*.txt`)**
Edit these files to change the core behavior of the agents:
- `therapist_prompt.txt`: Instructions for the AI Therapist.
- `patient_A_prompt.txt`: Base instructions for Patient A.
- `patient_B_prompt.txt`: Base instructions for Patient B.

**2. Personas (`prompts/trigger-personas.json`)**
Add or modify characters available for simulation.
```json
"New Character": {
  "name": "Alex",
  "age": 35,
  "occupation": "Engineer",
  "personality": "Logical, detached, avoids conflict...",
  "trigger_behavior": "Withdraws into silence when criticized"
}
```

---

## ğŸ› ï¸ UTILITY & VERIFICATION SCRIPTS

Used for testing and validating the system without running a full session.

### 1. Reproduce PANAS Analysis
**File**: `reproduce_panas.py`
- **Purpose**: Re-run the PANAS emotional scoring on an existing transcript json file. Useful if you want to tweak the scoring prompt or fix a parsing error without generating a new conversation.
- **Usage**: Edit the filename in the script and run `python reproduce_panas.py`.

### 2. Verify Reasoned Interventions
**File**: `verify_reasoning.py`
- **Purpose**: Test the intervention generation logic in isolation. It feeds a mock conversation and trigger to the LLM to verify it produces a valid response with the correct "voice".
- **Usage**: `python verify_reasoning.py`

### 3. Verify Console Display
**File**: `verify_display.py`
- **Purpose**: Test the rich console output formatting (summaries, stats) using dummy data.
- **Usage**: `python verify_display.py`

---

## ğŸ“ˆ RESEARCH WORKFLOW

### Phase 1: Validation
- [ ] Run 3 Sequential sessions
- [ ] Verify dialogue quality
- [ ] Confirm PANAS parsing works

### Phase 2: Ablation
- [ ] 10 sessions Ã— 3 structures = 30 sessions
- [ ] Compare PANAS outcomes
- [ ] Measure intervention effectiveness

### Phase 3: First Speaker Analysis
- [ ] 15 sessions varying first speaker
- [ ] Analyze PANAS deltas
- [ ] Statistical hypothesis testing

### Phase 4: Threshold Optimization
- [ ] Test INTERVENTION_THRESHOLD = 50, 60, 70, 80, 90
- [ ] Find sweet spot
- [ ] Correlate with quality

### Phase 5: Human Evaluation
- [ ] Have therapists rate interventions
- [ ] Collect feedback on appropriateness
- [ ] Iterate on prompt templates

### Phase 6: Publication
- [ ] Summarize findings
- [ ] Compare to related work
- [ ] Submit to ACL/therapy journals

---

## ğŸ“ ACADEMIC GROUNDING

### ACL Research Integration
- **FED Framework**: 4D intervention scoring reflects dialogue quality metrics
- **USR Framework**: Impact Potential dimension measures user satisfaction

### Therapeutic Practice
- **PANAS**: Validated 20-item emotion inventory (Watson & Clark, 1988)
- **Couples Therapy**: Multi-party dialogue with therapeutic balance

### Innovation
- Few systems combine trigger detection + LLM scoring + PANAS measurement
- Adaptive speaker selection with post-intervention control is novel

---

## ğŸ“š DOCUMENTATION

- **QUICK_START.md** - Installation & basic usage
- **REFACTORING_GUIDE.md** - Detailed module explanations
- **config.py** - Inline documentation of all constants
- **[Each module]** - Docstrings for all functions

---

## âœ… VALIDATION CHECKLIST

- [ ] All 10 modules created
- [ ] Imports work: `python -c "from config import *"`
- [ ] Assets load: Check chunks/, prompts/ directories
- [ ] .env file created with valid API key
- [ ] First test run: `python main.py`
- [ ] Output generated: Check transcripts/
- [ ] JSON valid: `python -c "import json; json.load(open('transcripts/therapy_transcript_1.json'))"`
- [ ] PANAS data present: Check Patient_A_PANAS_DELTA in JSON
- [ ] Summary displays: Check console output

---

## ğŸ†˜ TROUBLESHOOTING

| Error | Fix |
|-------|-----|
| `ModuleNotFoundError: config` | All .py files in same directory as main.py |
| `OPENAI_API_KEY not found` | Create .env with valid key |
| `FileNotFoundError: chunks/` | Move data files to correct location |
| PANAS parsing fails | Check panas_analyzer.py error message, adjust regex |
| Intervention score always 50 | Check JSON extraction in intervention_system.py |

---

## ğŸš€ NEXT STEPS

1. **Copy files** to your project directory
2. **Install dependencies**: `pip install openai python-dotenv`
3. **Create .env** with your OpenAI API key
4. **Run**: `python main.py`
5. **Check output**: `ls -lh transcripts/`
6. **Analyze**: Open JSON file, review results
7. **Iterate**: Modify config.py for experiments
8. **Publish**: Share findings with research community

---

## ğŸ“ SUPPORT

- Check docstrings in each module
- Review REFACTORING_GUIDE.md for details
- Read QUICK_START.md for setup
- Debug by adding print statements in specific modules

---

## ğŸ“ LICENSE & ATTRIBUTION

This modular refactoring maintains all functionality of the original test5.py while providing:
- Clear separation of concerns
- Production-ready architecture
- Research-grade output
- Extensible design for future work

---

**Status**: âœ… **COMPLETE & READY TO USE**

**Created**: January 8, 2026
**Version**: 2.1 (Modular + First Speaker + Persona Selection)

**Start with**: `QUICK_START.md` â†’ `python main.py` â†’ Check `transcripts/`

Good luck with your research! ğŸ“

---

## ğŸ“š Module Quick Reference

| Module | Purpose | Key Functions |
|--------|---------|---|
| **config.py** | Constants & settings | All configuration |
| **data_loader.py** | Load assets | `load_all_assets()` |
| **user_interface.py** | User input | `select_*` functions |
| **session_setup.py** | Initialize session | `setup_session_parameters()` |
| **conversation_engine.py** | Generate dialogue | `generate_agent_turn()` |
| **trigger_system.py** | Detect triggers | `detect_triggers()` |
| **intervention_system.py** | Score & generate interventions | `calculate_intervention_score()` |
| **panas_analyzer.py** | Emotional assessment | `compute_panas_delta()` |
| **output_manager.py** | Save & display results | `save_session_json()` |
| **main.py** | Orchestrate everything | `main()` |
