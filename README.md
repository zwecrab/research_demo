# README: MODULAR AI COUPLES THERAPY SIMULATION

## üéØ PROJECT SUMMARY

Status: ‚úÖ **ALL FILES CREATED & READY TO USE**

---

## üì¶ FILES CREATED (10 Modules + 2 Guides)

### Core Modules
1. ‚úÖ **config.py** - Configuration & constants
2. ‚úÖ **data_loader.py** - Asset loading (JSON, prompts)
3. ‚úÖ **user_interface.py** - CLI menu system
4. ‚úÖ **session_setup.py** - Session initialization
5. ‚úÖ **conversation_engine.py** - Dialogue generation & speaker selection
6. ‚úÖ **trigger_system.py** - Trigger detection (4 modalities)
7. ‚úÖ **intervention_system.py** - LLM scoring & intervention generation
8. ‚úÖ **panas_analyzer.py** - Emotional assessment (pre/post)
9. ‚úÖ **output_manager.py** - File I/O & summaries
10. ‚úÖ **main.py** - Orchestrator (ties everything together)

### Documentation
11. ‚úÖ **REFACTORING_GUIDE.md** - Detailed module explanations
12. ‚úÖ **QUICK_START.md** - Installation & getting started

---

## üöÄ QUICK START

### Step 1: Copy Files to Project Directory
```
your_project/
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ data_loader.py
‚îú‚îÄ‚îÄ user_interface.py
‚îú‚îÄ‚îÄ session_setup.py
‚îú‚îÄ‚îÄ conversation_engine.py
‚îú‚îÄ‚îÄ trigger_system.py
‚îú‚îÄ‚îÄ intervention_system.py
‚îú‚îÄ‚îÄ panas_analyzer.py
‚îú‚îÄ‚îÄ output_manager.py
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ .env (create this)
```

### Step 2: Install Dependencies
```bash
pip install openai python-dotenv
```

### Step 3: Create .env File
```
OPENAI_API_KEY=sk-your-key-here
```

### Step 4: Run
```bash
python main.py
```

---

## üìä MODULE DEPENDENCY DIAGRAM

```
main.py (Orchestrator)
    ‚Üì
    ‚îú‚îÄ‚Üí data_loader.py (Load assets)
    ‚îú‚îÄ‚Üí user_interface.py (User input)
    ‚îú‚îÄ‚Üí session_setup.py (Initialize session)
    ‚îú‚îÄ‚Üí conversation_engine.py (Generate dialogue)
    ‚îÇ   ‚îî‚îÄ‚Üí config.py (Models, temperature)
    ‚îú‚îÄ‚Üí trigger_system.py (Detect triggers)
    ‚îú‚îÄ‚Üí intervention_system.py (Score & generate)
    ‚îú‚îÄ‚Üí panas_analyzer.py (Emotional analysis)
    ‚îî‚îÄ‚Üí output_manager.py (Save results)
```

---

## üéõÔ∏è USER FLOW

```
START
  ‚Üì
1. Select Session Topic
  ‚îú‚îÄ ALCOHOL ABUSE
  ‚îú‚îÄ ANXIETY
  ‚îú‚îÄ CONFLICT
  ‚îî‚îÄ (etc.)
  ‚Üì
2. Select Temperature (0.0-1.0)
  ‚îú‚îÄ 0.0 = Deterministic
  ‚îú‚îÄ 0.5 = Balanced
  ‚îî‚îÄ 1.0 = Creative
  ‚Üì
3. Select Conversation Structure
  ‚îú‚îÄ Sequential (fixed rotation)
  ‚îú‚îÄ LLM Only (intelligent selection, no triggers)
  ‚îî‚îÄ LLM with Triggers (full system) ‚Üê NEW
  ‚Üì
4. (If LLM+Triggers) Select Trigger Type
  ‚îú‚îÄ Direct Intervention Request
  ‚îú‚îÄ Time-based Analysis
  ‚îú‚îÄ Semantic Analysis
  ‚îú‚îÄ Quantitative Analysis
  ‚îî‚îÄ All Triggers
  ‚Üì
5. (NEW!) Select First Speaker
  ‚îú‚îÄ Patient A (affected party)
  ‚îú‚îÄ Patient B (supporting partner)
  ‚îú‚îÄ Random
  ‚Üì
6. (NEW!) Persona Selection
  ‚îú‚îÄ Random (default)
  ‚îú‚îÄ Manual Selection (browse & choose specific personas)
  ‚Üì
[SIMULATION RUNS: 25-35 turns]
  ‚Üì
[POST-SESSION PANAS ANALYSIS]
  ‚Üì
[OUTPUT: JSON transcript, summary, report]
  ‚Üì
END
```

---

## üìã FEATURE BREAKDOWN

### Trigger Detection (4 Modalities)

| Trigger | Detection | Example |
|---------|-----------|---------|
| **Direct Request** | Keywords | "Can you help us?" |
| **Time-based** | Silence >30s | Speaker hasn't spoken 3+ turns |
| **Semantic** | Escalation + self-harm | "I HATE this!!! I want to die" |
| **Quantitative** | Dominance + word count | 6+ consecutive messages or 100+ words |

### Intervention Scoring (4 Dimensions)

| Dimension | Scale | Meaning |
|-----------|-------|---------|
| Flow Disruption | 0-100 | How jarring would interruption be? |
| Therapeutic Need | 0-100 | Is there genuine distress? |
| Timing | 0-100 | Is it a natural pause point? |
| Impact | 0-100 | Will it help (USR framework)? |
| **Average** | **0-100** | **Trigger threshold: ‚â•70** |
 
### Intervention Transparency
- **Reasoning**: The system now provides an explicit explanation for *why* an intervention was triggered, referencing the specific scoring dimension and observed behavior.

### PANAS Emotional Assessment

**20 Emotions measured:**
- **10 Positive**: Interested, Excited, Strong, Enthusiastic, Proud, Alert, Inspired, Determined, Attentive, Active
- **10 Negative**: Distressed, Upset, Guilty, Scared, Hostile, Irritable, Ashamed, Nervous, Jittery, Afraid

**Outcome Metrics:**
- Pre-session baseline (from persona)
- Post-session scoring (LLM evaluated)
- Delta calculation (improvement measure)

---

## üí° KEY INNOVATIONS

### 1. Four-Dimensional Intervention Scoring
‚Üí Not just *when* to intervene (triggers), but *whether* intervening will help (clinical reasoning)

### 2. NEW: First Speaker & Persona Selection
‚Üí Research design feature: control exactly *who* speaks first and *which* specific persona characteristics are active.

### 3. Modular Architecture
‚Üí Test components independently (Sequential vs LLM Only vs LLM+Triggers)

### 4. PANAS Pre/Post Assessment
‚Üí Empirical outcome measurement (emotional state improvement)

---

## üß™ EXPERIMENT EXAMPLES

### Experiment 1: Baseline (Sequential)
```
Structure: Sequential (Therapist ‚Üí Patient A ‚Üí Patient B cycle)
Triggers: Disabled
First Speaker: (N/A)
‚Üí Output: Pure dialogue without AI interference
```

### Experiment 2: Speaker Selection
```
Structure: LLM Only
Triggers: Disabled
First Speaker: Patient A
‚Üí Output: Intelligent speaker balancing
```

### Experiment 3: Full System
```
Structure: LLM with Triggers
Trigger Type: Semantic Analysis
First Speaker: Patient B
‚Üí Output: Full adaptive facilitation with emotional crisis detection
```

### Experiment 4: First Speaker Ablation
```
Run 3 sessions, vary first speaker:
- Patient A first
- Patient B first
- Random

‚Üí Compare PANAS deltas across sessions
```

---

## üìä OUTPUT FILES

### Generated Files
```
transcripts/
‚îú‚îÄ‚îÄ therapy_transcript_1.json          # Full session data
‚îú‚îÄ‚îÄ therapy_transcript_2.json          # Next session
‚îú‚îÄ‚îÄ transcript_readable_*.txt          # Human-readable format
‚îî‚îÄ‚îÄ (auto-incremented numbering)
```

### JSON Structure
```json
{
  "session_topic_header": "ALCOHOL ABUSE",
  "conversation_structure": "LLM with Triggers",
  "first_speaker_selection": "Patient A",  ‚Üê NEW
  "session_transcript": [
    {
      "turn": 1,
      "speaker": "Therapist",
      "dialogue": "..."
    },
    ...
  ],
  "intervention_count": 3,
  "Patient_A_PANAS_DELTA": [
    {"feeling": "Interested", "before_score": 3, "after_score": 4, "difference": 1}
  ]
}
```

---

## üîß CUSTOMIZATION

### Change Intervention Threshold
**File**: `config.py`
```python
INTERVENTION_THRESHOLD = 70  # Change to 50, 60, 80, etc.
```

### Add New Trigger Type
**File**: `trigger_system.py`
```python
def detect_my_trigger(message):
    return "pattern" in message.lower()

# In detect_triggers():
if selected_trigger == "My Trigger":
    if detect_my_trigger(current_message):
        triggers_detected.append({...})
```

### Change Model
**File**: `config.py`
```python
CONVERSATION_MODEL = "gpt-4-turbo"  # Or any OpenAI model
```

---

## üìà RESEARCH WORKFLOW

### Phase 1: Validation
- [ ] Run 3 Sequential sessions
- [ ] Verify dialogue quality
- [ ] Confirm PANAS parsing works

### Phase 2: Ablation
- [ ] 10 sessions √ó 3 structures = 30 sessions
- [ ] Compare PANAS outcomes
- [ ] Measure intervention effectiveness

### Phase 3: First Speaker Analysis
- [ ] 15 sessions varying first speaker
- [ ] Analyze PANAS deltas
- [ ] Statistical hypothesis testing

### Phase 4: Threshold Optimization
- [ ] Test INTERVENTION_THRESHOLD = 50, 60, 70, 80, 90
- [ ] Find sweet spot
- [ ] Correlate with quality

### Phase 5: Human Evaluation
- [ ] Have therapists rate interventions
- [ ] Collect feedback on appropriateness
- [ ] Iterate on prompt templates

### Phase 6: Publication
- [ ] Summarize findings
- [ ] Compare to related work
- [ ] Submit to ACL/therapy journals

---

## üéì ACADEMIC GROUNDING

### ACL Research Integration
- **FED Framework**: 4D intervention scoring reflects dialogue quality metrics
- **USR Framework**: Impact Potential dimension measures user satisfaction

### Therapeutic Practice
- **PANAS**: Validated 20-item emotion inventory (Watson & Clark, 1988)
- **Couples Therapy**: Multi-party dialogue with therapeutic balance

### Innovation
- Few systems combine trigger detection + LLM scoring + PANAS measurement
- Adaptive speaker selection with post-intervention control is novel

---

## üìö DOCUMENTATION

- **QUICK_START.md** - Installation & basic usage
- **REFACTORING_GUIDE.md** - Detailed module explanations
- **config.py** - Inline documentation of all constants
- **[Each module]** - Docstrings for all functions

---

## ‚úÖ VALIDATION CHECKLIST

- [ ] All 10 modules created
- [ ] Imports work: `python -c "from config import *"`
- [ ] Assets load: Check chunks/, prompts/ directories
- [ ] .env file created with valid API key
- [ ] First test run: `python main.py`
- [ ] Output generated: Check transcripts/
- [ ] JSON valid: `python -c "import json; json.load(open('transcripts/therapy_transcript_1.json'))"`
- [ ] PANAS data present: Check Patient_A_PANAS_DELTA in JSON
- [ ] Summary displays: Check console output

---

## üÜò TROUBLESHOOTING

| Error | Fix |
|-------|-----|
| `ModuleNotFoundError: config` | All .py files in same directory as main.py |
| `OPENAI_API_KEY not found` | Create .env with valid key |
| `FileNotFoundError: chunks/` | Move data files to correct location |
| PANAS parsing fails | Check panas_analyzer.py error message, adjust regex |
| Intervention score always 50 | Check JSON extraction in intervention_system.py |

---

## üöÄ NEXT STEPS

1. **Copy files** to your project directory
2. **Install dependencies**: `pip install openai python-dotenv`
3. **Create .env** with your OpenAI API key
4. **Run**: `python main.py`
5. **Check output**: `ls -lh transcripts/`
6. **Analyze**: Open JSON file, review results
7. **Iterate**: Modify config.py for experiments
8. **Publish**: Share findings with research community

---

## üìû SUPPORT

- Check docstrings in each module
- Review REFACTORING_GUIDE.md for details
- Read QUICK_START.md for setup
- Debug by adding print statements in specific modules

---

## üìù LICENSE & ATTRIBUTION

This modular refactoring maintains all functionality of the original test5.py while providing:
- Clear separation of concerns
- Production-ready architecture
- Research-grade output
- Extensible design for future work

---

**Status**: ‚úÖ **COMPLETE & READY TO USE**

**Created**: January 8, 2026
**Version**: 2.1 (Modular + First Speaker + Persona Selection)

**Start with**: `QUICK_START.md` ‚Üí `python main.py` ‚Üí Check `transcripts/`

Good luck with your research! üéì

---

## üìö Module Quick Reference

| Module | Purpose | Key Functions |
|--------|---------|---|
| **config.py** | Constants & settings | All configuration |
| **data_loader.py** | Load assets | `load_all_assets()` |
| **user_interface.py** | User input | `select_*` functions |
| **session_setup.py** | Initialize session | `setup_session_parameters()` |
| **conversation_engine.py** | Generate dialogue | `generate_agent_turn()` |
| **trigger_system.py** | Detect triggers | `detect_triggers()` |
| **intervention_system.py** | Score & generate interventions | `calculate_intervention_score()` |
| **panas_analyzer.py** | Emotional assessment | `compute_panas_delta()` |
| **output_manager.py** | Save & display results | `save_session_json()` |
| **main.py** | Orchestrate everything | `main()` |
